{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tINRhKuwC89m"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "EyD2S81EC5yq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import statsmodels.formula.api as smf\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.decomposition import PCA\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "rankings = {'Easy': 1, 'Medium': 2, 'Hard': 3}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCmL2HQCDyn0"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "nihQIHADDzEH"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "  v1 = np.array(v1).flatten()\n",
        "  v2 = np.array(v2).flatten()\n",
        "  return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "\n",
        "def return_emb(word, source_emb):\n",
        "  try:\n",
        "    emb = source_emb[word]\n",
        "    return word\n",
        "  except KeyError:\n",
        "    word_stem = ps.stem(word)\n",
        "    try:\n",
        "      emb = source_emb[word_stem]\n",
        "      return word_stem\n",
        "    except KeyError:\n",
        "      return np.NaN\n",
        "\n",
        "def return_clue(data):\n",
        "  values = []\n",
        "  options = ['clueOption1', 'clueOption2', 'clueOption3', 'clueOption4', 'clueOption5', 'clueOption6', 'clueOption7', 'clueOption8']\n",
        "  for i in range(len(data)):\n",
        "    row = data.loc[i, options].dropna().to_list()\n",
        "    try:\n",
        "      option = row.index(data.loc[i, 'clueFinal'])\n",
        "      values.append(int(options[option].lstrip('clueOption')))\n",
        "    except ValueError:\n",
        "      values.append(None)\n",
        "  return values\n",
        "\n",
        "def return_guess(data):\n",
        "  values = {'GUESS_1_FINAL': [], 'GUESS_2_FINAL': []}\n",
        "  options = ['GuessOption1', 'GuessOption2', 'GuessOption3', 'GuessOption4', 'GuessOption5', 'GuessOption6', 'GuessOption7', 'GuessOption8']\n",
        "  guesses = ['GUESS_1_FINAL', 'GUESS_2_FINAL']\n",
        "  for i in range(len(data)):\n",
        "    row = data.loc[i, options].dropna().to_list()\n",
        "    finals = data.loc[i, guesses]\n",
        "    for f in guesses:\n",
        "      try:\n",
        "        option = row.index(finals[f])\n",
        "        values[f].append(int(options[option].lstrip('GuessOption')))\n",
        "      except ValueError:\n",
        "        values[f].append(None)\n",
        "  return values.values()\n",
        "\n",
        "def load_online_data(online_path = \"./data/online.csv\"):\n",
        "  online = pd.read_csv(online_path)\n",
        "  online['Ranking'] = online['Level'].apply(lambda x: rankings[x])\n",
        "  online_clues = online.loc[:, ['wordpair_id', 'gameID', 'clueOption1', 'clueOption2', 'clueOption3', 'clueOption4', 'clueOption5', 'clueOption6', 'clueOption7', 'clueOption8', 'clueFinal', 'Acc', 'Level', 'Ranking']]\n",
        "  online_unique_clues = online[['wordpair_id', 'gameID', 'clueOption1', 'clueOption2', 'clueOption3', 'clueOption4', 'clueOption5', 'clueOption6', 'clueOption7', 'clueOption8', 'target1', 'target2']]\n",
        "  online_clues['Number of Clues'] = [len(online_unique_clues.loc[i,:].dropna().to_list()) for i in range(len(online_clues))]\n",
        "  online_guesses = online.loc[:, ['wordpair_id', 'gameID', 'GuessOption1', 'GuessOption2', 'GuessOption3', 'GuessOption4', 'GuessOption5', 'GuessOption6', \n",
        "                                  'GuessOption7', 'GuessOption8', \"target1\", \"target2\"]]\n",
        "  online.to_csv(r\"./data/candidate-generation.csv\", index = False)\n",
        "  return online, online_clues, online_unique_clues, online_guesses\n",
        "\n",
        "def load_embeddings_data(swow_path = \"./data/swow_embeddings.csv\"):\n",
        "  return pd.read_csv(swow_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "########### Extract Online\n",
        "online, online_clues, online_unique_clues, online_guesses = load_online_data()\n",
        "\n",
        "#glove_path = parentdirectory + \"glove_embeddings.csv\"\n",
        "swow = load_embeddings_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1h_OWB4BpeW"
      },
      "source": [
        "# *Searching for multiple concepts within semantic memory*\n",
        "\n",
        "Collin J. Kovacs, Jasper M. Wilson, and Abhilasha A. Kumar\n",
        "\n",
        "[Latex paper draft](https://www.overleaf.com/3682451699jnphdztfwskz)\n",
        "\n",
        "There is not a lot of work investigating the explicit search processes in ambiguous multi-referent contexts. Previous work in this area has shown that speakers tend to use some form of context sensitivity judgment and pragmatic inference to come up with the final response, BUT the explicit generation process remains obscure in these communication tasks. How might we study this process by which an individual arrives upon the final referent? In this work, we introduce and evaluate a think-aloud paradigm for capturing interim responses during semantic search, borrowing from tasks such as fluency and variants of RAT. (explain task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-QmA2MtCw8S"
      },
      "source": [
        "We evaluate whether the responses show signatures of clustering and/or foraging typically found in semantic retrieval tasks. we use a patchy semantic space and ask whether the candidate responses show any evidence of transitions within and outside the patch, and whether these are related to correct responses from the listener. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "WgLWjXjsCxiV"
      },
      "outputs": [],
      "source": [
        "def _patch1(data = online):\n",
        "  wpid = data['wordpair_id'].unique()\n",
        "  rows = []\n",
        "  for t in wpid:\n",
        "    temp = online[online['wordpair_id'] == t].reset_index()\n",
        "    temp = temp.loc[:, ['wordpair_id', 'gameID', 'clueOption1', 'target1', 'target2', 'Level', 'Acc', 'clueFinal']].reset_index(drop = True)\n",
        "    row_frame = temp[['gameID', 'clueFinal', 'Acc', 'Level']]\n",
        "    row_frame['wordpair_id'] = t\n",
        "    row_frame['target1'] = temp.loc[0, 'target1']\n",
        "    row_frame['target2'] = temp.loc[0, 'target2']\n",
        "    clues = list(temp['clueOption1'].unique())\n",
        "    row_frame['words_in_patch'] = ','.join(clues)\n",
        "    row_frame['patchsize'] = len(clues)\n",
        "    row_frame['Level'] = temp.loc[0, 'Level']\n",
        "\n",
        "    rows.append(row_frame)\n",
        "\n",
        "  frame = pd.concat(rows).reset_index(drop = True).rename({'index': 'row_id'}, axis = 1)\n",
        "  return frame\n",
        "\n",
        "def _movement(words):\n",
        "  first, second = words\n",
        "  if first[1] == 1 and second[1] == 1:\n",
        "    return 'In-In'\n",
        "  elif first[1] == 1 and second[1] == 0:\n",
        "    return 'In-Out'\n",
        "  elif first[1] == 0 and second[1] == 1:\n",
        "    return 'Out-In'\n",
        "  else:\n",
        "    return 'Out-Out'\n",
        "\n",
        "def _determine_movement(patch_data, typ):\n",
        "  temp_options = online[['wordpair_id', 'gameID', 'clueOption1', 'clueOption2', 'clueOption3','clueOption4', 'clueOption5', 'clueOption6', 'clueOption7', 'clueOption8', 'clueFinal', 'Acc']]\n",
        "  temp_options = temp_options.reset_index().rename({'index': 'row_id'}, axis = 1)\n",
        "  rows = []\n",
        "  for i in tqdm(range(len(temp_options))):\n",
        "    r = {}\n",
        "    row = temp_options.loc[i, :].dropna()\n",
        "    r['wordpair_id'] = row.wordpair_id\n",
        "    r['gameID'] = row.gameID\n",
        "    r['In-In'] = 0\n",
        "    r['In-Out'] = 0\n",
        "    r['Out-In'] = 0\n",
        "    r['Out-Out'] = 0\n",
        "\n",
        "    words = list(row.drop(['wordpair_id', 'Acc', 'clueFinal']).to_list())\n",
        "    words = [w for w in words if isinstance(w, str)]\n",
        "    patch_wordpair = patch_data.loc[patch_data['wordpair_id'] == row.wordpair_id, :]\n",
        "    words_in_patch = [(w, 1) if w in patch_wordpair['words_in_patch'].to_list()[0].split(',') else (w, 0) for w in words ]\n",
        "    perms = [(words_in_patch[i], words_in_patch[i+1]) for i in range(0, len(words_in_patch)-1)]\n",
        "    movements = pd.Series([_movement(p) for p in perms])\n",
        "    ps = pd.DataFrame(movements.value_counts().reset_index()).rename({'index': 'Type', 0: 'Count'}, axis = 1)\n",
        "\n",
        "    ps_d = dict(zip(ps['Type'], ps['Count']))\n",
        "    for k, v in ps_d.items():\n",
        "      r[k] = v\n",
        "    r['Acc'] = row.Acc\n",
        "    r['ClueFinal'] = row.clueFinal\n",
        "    rows.append(r)\n",
        "    \n",
        "  total = pd.DataFrame.from_dict(rows)\n",
        "  return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5uuWHK7W47w",
        "outputId": "5ba2fcfe-1773-42cd-aa6e-7bf49ebb3a82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1456/1456 [00:02<00:00, 674.28it/s]\n"
          ]
        }
      ],
      "source": [
        "patch1 = _patch1()\n",
        "patch1.to_csv(r\"./data/in_out_transitions.csv\", index = False)\n",
        "\n",
        "movement1 = _determine_movement(patch1, 'NumberOfUniqueClues')\n",
        "movement1.to_csv(r\"./data/patch_words.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each sequence of candidates generated by a person (lighter-flash-bright-lightning), find out whether they are closer to one word (quick) or another (glow) and assign a 1 or 2 to each candidate response (use swow embeddings for determining semantic similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Predictions:\n",
        "  swow_similarity: pd.DataFrame = None\n",
        "\n",
        "  def __init__(self, \n",
        "               clue: pd.DataFrame = online_unique_clues, \n",
        "               emb_class: pd.DataFrame = swow):\n",
        "    self.processed_path = \"./data\"\n",
        "    self.clue = clue\n",
        "    self.melted_clue = self._melt_clue()\n",
        "    self.embeddings = self._create_embeddings()\n",
        "\n",
        "    if Predictions.swow_similarity is None:\n",
        "      Predictions.swow_similarity = self.swow_similarity_clustering()\n",
        "\n",
        "  def _melt_clue(self):\n",
        "    melted_clue = pd.melt(self.clue, id_vars = ['wordpair_id', 'gameID', 'target1', 'target2']).sort_values(['target1', 'target2']).dropna().reset_index(drop = True)\n",
        "    melted_clue['value'] = melted_clue['value'].str.lower()\n",
        "    return melted_clue\n",
        "\n",
        "  def _create_embeddings(self):\n",
        "    all_words = pd.Series(self.melted_clue['target1'].to_list() + self.melted_clue['target2'].to_list() + self.melted_clue['value'].to_list())\n",
        "    unq_words = list(set(all_words))\n",
        "    rows = []\n",
        "    index_ = []\n",
        "    none_vector = [np.NaN for _ in range(300)]\n",
        "    for word in unq_words:\n",
        "\n",
        "      # collect the embeddings for the targets and the given word\n",
        "      try:\n",
        "        emb = swow[return_emb(word, source = 'swow')].values.tolist()\n",
        "      except:\n",
        "        emb = none_vector\n",
        "\n",
        "      rows.append(emb)\n",
        "      index_.append(word)\n",
        "    emb_data = pd.DataFrame(rows, index = index_)\n",
        "    emb_data = emb_data.reset_index().rename({'index': 'value'}, axis = 1)\n",
        "    return emb_data\n",
        "\n",
        "  def swow_similarity_clustering(self):\n",
        "    swow_path = os.path.join(self.processed_path, 'swow_arc.csv')\n",
        "    if os.path.exists(swow_path):\n",
        "      return pd.read_csv(swow_path)\n",
        "\n",
        "    swow_data = self.melted_clue.copy()\n",
        "    closesttarget = []\n",
        "    for i, row in tqdm(self.melted_clue.iterrows()):\n",
        "      target1, target2, word = row.target1, row.target2, row.value\n",
        "      \n",
        "      # extract words and check if the word is None\n",
        "      target1 = self.embeddings[self.embeddings.value == target1].drop('value', axis = 1).values\n",
        "      target2 = self.embeddings[self.embeddings.value == target2].drop('value', axis = 1).values\n",
        "      word = self.embeddings[self.embeddings.value == word].drop('value', axis = 1).values\n",
        "\n",
        "      if word is not None:\n",
        "        sim_target1_word = cosine_similarity(target1, word)\n",
        "        sim_target2_word = cosine_similarity(target2, word)\n",
        "      else:\n",
        "        sim_target1_word = sim_target2_word = 0\n",
        "\n",
        "      # find similarity\n",
        "      if sim_target1_word > sim_target2_word:\n",
        "        closesttarget.append(1)\n",
        "      else:\n",
        "        closesttarget.append(2)\n",
        "\n",
        "    swow_data['Prediction_SWOW'] = closesttarget\n",
        "    swow_data = swow_data.sort_values(['wordpair_id', 'gameID', 'variable']).reset_index(drop = True)\n",
        "    swow_data.to_csv(swow_path, index = False)\n",
        "    return swow_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = Predictions()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOVXA20kgbvBp2lLmJdvWMn",
      "include_colab_link": true,
      "name": "paper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
